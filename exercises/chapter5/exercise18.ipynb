{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ba11a8-9964-4b7e-b262-8b631b887188",
   "metadata": {},
   "source": [
    "# Exercise 17 - Variations of Physics-Informed Neural Networks\n",
    "### Task\n",
    "1. The main variations of PINNs are studied. Go to block 15 to choose the cost function of:\n",
    "- Physics-informed neural network (PINN)\n",
    "- Discrete Galerkin method (DGM)\n",
    "- Deep energy method (DEM) (to see the cost history, remove the logscale in block 20) \n",
    "- Variational physics-informed neural network (VPINN)\n",
    "\n",
    "To use the\n",
    "\n",
    "- Weak adversarial network (WAN)\n",
    "\n",
    "use the VPINN cost function and uncomment the neural network (modelW) for the test functions in block 18\n",
    "\n",
    "2. Next, switch to the problem b (see the exercise description) in block 15. The problem is, that there is a weak singularity at the left edge. By changing the integration technique in block 4 to midPointIntegration, the singularity is no longer evaluated. Compare the PINN and the DEM for case b. What happens if you reduce the number of collocation points Nx in block 16 (also reduce the number of epochs for DEM to prevent overfitting)?\n",
    "\n",
    "Note that the boundary conditions are implemented differently and in a less general manner. The getDisplacements function checks for homogeneous Dirichlet boundary conditions on the left and right edge (block 7), while inhomogeneous Neumann boundary conditions are checked directly in the different cost functions (block 10-13).\n",
    "\n",
    "### Learning goals\n",
    "- Understand the differences between the main PINN variations\n",
    "- Be able to implement the main PINN variations\n",
    "- Gain intuition on the capabilities of the PINN variations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc65ef-fdb0-409a-8b58-6ee22a3a38db",
   "metadata": {},
   "source": [
    "**import libraries & set seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfeb949-ac58-4b07-9687-c41064b91f0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:13:11.088559095Z",
     "start_time": "2024-02-01T08:13:10.988656564Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import grad\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3288adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a287a8dc-3ef0-490c-a549-a4c06474f8b9",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3837a3c0-c7e6-4750-94d6-07b83721493f",
   "metadata": {},
   "source": [
    "**gradient computation with automatic differentiation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9ff7cc-b51d-4a65-b314-06d55506104a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:13:11.092776514Z",
     "start_time": "2024-02-01T08:13:11.080661941Z"
    }
   },
   "outputs": [],
   "source": [
    "def getDerivative(y, x, n):\n",
    "    \"\"\"Compute the nth order derivative of y = f(x) with respect to x.\"\"\"\n",
    "\n",
    "    if n == 0:\n",
    "        return y\n",
    "    else:\n",
    "        dy_dx = grad(\n",
    "            y, x, torch.ones(x.size()[0], 1), create_graph=True, retain_graph=True\n",
    "        )[0]\n",
    "        return getDerivative(dy_dx, x, n - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b29b4e-25a6-4a63-bc6c-e4131e29934b",
   "metadata": {},
   "source": [
    "**numerical integration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d2b01f-63b0-4a45-8e1b-71e93ce41a4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:13:11.143376619Z",
     "start_time": "2024-02-01T08:13:11.095967873Z"
    }
   },
   "outputs": [],
   "source": [
    "def midpointIntegration(y, x):\n",
    "    dx = x[1] - x[0]  # Compute delta x assuming it's constant over the range of x\n",
    "\n",
    "    return torch.sum(y, axis=0) * dx\n",
    "\n",
    "\n",
    "def trapezoidalIntegration(y, x):\n",
    "    dx = x[1] - x[0]  # Compute delta x assuming it's constant over the range of x\n",
    "\n",
    "    # Compute the integral with the trapezoidal rule\n",
    "    result = torch.sum(y, axis=0)\n",
    "    result = result - (y[0] + y[-1]) / 2\n",
    "\n",
    "    return result * dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407360b6-5c58-449f-93f5-df8fa6fc6ff6",
   "metadata": {},
   "source": [
    "**select numerical integration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8c7df8-d07c-4b52-894b-cb37f4d149e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:13:11.158431960Z",
     "start_time": "2024-02-01T08:13:11.143787666Z"
    }
   },
   "outputs": [],
   "source": [
    "# getIntegral = midpointIntegration\n",
    "getIntegral = trapezoidalIntegration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3351b4bd-8953-4816-87ac-fd5abb029b75",
   "metadata": {},
   "source": [
    "**neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa82fc-8100-4a35-9709-9f3ff1272515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:13:11.169485731Z",
     "start_time": "2024-02-01T08:13:11.158014333Z"
    }
   },
   "outputs": [],
   "source": [
    "class NN(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            inputDimension,\n",
    "            hiddenDimensions,\n",
    "            outputDimension,\n",
    "            activationFunction=torch.nn.Tanh(),\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        modules = []\n",
    "\n",
    "        modules.append(torch.nn.Linear(inputDimension, hiddenDimensions[0]))\n",
    "        modules.append(activationFunction)\n",
    "        for i in range(len(hiddenDimensions) - 1):\n",
    "            modules.append(\n",
    "                torch.nn.Linear(hiddenDimensions[i], hiddenDimensions[i + 1])\n",
    "            )\n",
    "            modules.append(activationFunction)\n",
    "        modules.append(torch.nn.Linear(hiddenDimensions[-1], outputDimension))\n",
    "\n",
    "        self.model = torch.nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2997a44b-2089-42b8-b3cc-dcb75599c2d7",
   "metadata": {},
   "source": [
    "**initialization of neural network weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccef84d-eadf-4dc1-8298-b1062faa5f97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:13:11.173559960Z",
     "start_time": "2024-02-01T08:13:11.162436874Z"
    }
   },
   "outputs": [],
   "source": [
    "def initWeights(m):\n",
    "    \"\"\"Initialize weights of neural network with xavier initialization.\"\"\"\n",
    "    if type(m) == torch.nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(\n",
    "            m.weight, gain=torch.nn.init.calculate_gain(\"tanh\")\n",
    "        )  # adapt if using a different initialization\n",
    "        m.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac280a6c-0742-4bf8-b6f2-0995b3680079",
   "metadata": {},
   "source": [
    "## PINN helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f551c1ad-ef82-4af5-bc7c-658fb6d16913",
   "metadata": {},
   "source": [
    "**displacement computation**\n",
    "$$\\hat{u}=F_{NN}(x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eda658-51ba-47bc-a7ff-ed2bb47c4c42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:13:11.204900819Z",
     "start_time": "2024-02-01T08:13:11.173230911Z"
    }
   },
   "outputs": [],
   "source": [
    "def getDisplacements(model, x, uB, L):  # only works for homogeneous boundary conditions\n",
    "    u = model(x)\n",
    "    if np.any(np.all(np.array(uB) == [0, 0, 0], axis=1)):\n",
    "        u *= x\n",
    "    if np.any(np.all(np.array(uB) == [0, 0, L], axis=1)):\n",
    "        u *= L - x\n",
    "\n",
    "    return u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e642202-4b74-4cb5-be84-4411c2d0efb5",
   "metadata": {},
   "source": [
    "**test functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01a7c29-bb3d-4405-9e95-e679bb193469",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:13:11.216542174Z",
     "start_time": "2024-02-01T08:13:11.204483121Z"
    }
   },
   "outputs": [],
   "source": [
    "class testFunctions(torch.nn.Module):\n",
    "    def __init__(self, x, n, L):\n",
    "        super().__init__()\n",
    "        self.paramters = None\n",
    "\n",
    "        self.testFunctions = torch.zeros((len(x), n))\n",
    "        for i in range(n):\n",
    "            self.testFunctions[:, i] = 1.0 - torch.cos(\n",
    "                (i + 1) * np.pi / L * x[:, 0]\n",
    "            )  # assumes a Dirichlet boundary condition at the left edge\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.clone(\n",
    "            self.testFunctions\n",
    "        )  # necessary as it is otherwise directly modified in getTestFunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84c7c1c74b92a5f",
   "metadata": {},
   "source": [
    "**test function computation with consideration of Dirichlet boundary conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b657d931edd6836a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:13:11.225189076Z",
     "start_time": "2024-02-01T08:13:11.216221249Z"
    }
   },
   "outputs": [],
   "source": [
    "def getTestFunctions(model, x, uB, L):\n",
    "    w = model(x)\n",
    "    if np.any(np.all(np.array(uB)[:, 1:] == [0, 0], axis=1)):\n",
    "        w *= x\n",
    "    if np.any(np.all(np.array(uB)[:, 1:] == [0, L], axis=1)):\n",
    "        w *= L - x\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9999f25-b7e7-42fa-a1bd-4824a0a32fa3",
   "metadata": {},
   "source": [
    "**cost function computation**\n",
    "\n",
    "## Physics-informed loss function\n",
    "The differential equation loss\n",
    "$$\\mathcal{L}_\\mathcal{N}=\\sum_{i=1}^N\\bigl(\\frac{d}{dx}EA(x_i)\\bigl(\\frac{d\\hat{u}(x_i)}{dx}\\bigr)+p(x_i)\\bigr)^2$$\n",
    "The boundary condition loss \n",
    "$$\\mathcal{L}_\\mathcal{B}=\\sum_{i=1}^{N_B}\\bigl( \\frac{d^{n_i} \\hat{u}(x_i)}{dx^{n_i}} - F_i \\bigr)^2$$\n",
    "$$C = \\mathcal{L}_\\mathcal{N} + \\mathcal{L}_\\mathcal{B}$$\n",
    "\n",
    "## Deep Galerkin method\n",
    "The differential equation loss\n",
    "$$\\mathcal{L}_\\mathcal{N}=\\int_0^L \\bigl(\\frac{d}{dx}EA(x)\\bigl(\\frac{d\\hat{u}(x)}{dx}\\bigr)+p(x)\\bigr)^2 v(x) dx$$\n",
    "$$v(x)\\sim U(0,1)$$\n",
    "The boundary condition loss \n",
    "$$\\mathcal{L}_\\mathcal{B}=\\sum_{i=1}^{N_B}\\bigl( \\frac{d^{n_i} \\hat{u}(x_i)}{dx^{n_i}} - F_i \\bigr)^2$$\n",
    "$$C = \\mathcal{L}_\\mathcal{N} + \\mathcal{L}_\\mathcal{B}$$\n",
    "\n",
    "## Variational physics-informed neural networks\n",
    "$$C = \\sum_{i=1}^{N_{\\mathcal{W}}} \\Bigl( -\\int_0^L \\frac{du(x)}{dx}EA(x)\\frac{dw_i(x)}{dx} dx + \\int_0^L p(x) w_i(x) dx + \\int_{\\Gamma_N} \\frac{du(x)}{dx}EA(x) w_i(x)d\\Gamma_N \\Bigr)^2$$\n",
    "\n",
    "## Weak adversarial networks\n",
    "$$C = \\sum_{i=1}^{N_{\\mathcal{W}}} \\Bigl( -\\int_0^L \\frac{du(x)}{dx}EA(x)\\frac{d\\hat{w}_i(x)}{dx} dx + \\int_0^L p(x) \\hat{w}_i(x) dx + \\int_{\\Gamma_N} \\frac{du(x)}{dx}EA(x) \\hat{w}_i(x)d\\Gamma_N \\Bigr)^2$$\n",
    "$$\\min_u \\max_w C$$\n",
    "\n",
    "## Deep energy method\n",
    "internal energy\n",
    "$$\\Pi_{int} = \\frac{1}{2} \\int_0^L \\bigl(\\frac{du(x)}{dx}\\bigr)^2 EA(x)dx$$\n",
    "external energy\n",
    "$$\\Pi_{ext} = - \\int_0^L p(x) u(x) dx - \\int_{\\Gamma_N} \\frac{du(x)}{dx}EA(x) u(x)d\\Gamma_N $$\n",
    "$$C = \\Pi_{int} + \\Pi_{ext}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350e68ec03138984",
   "metadata": {},
   "source": [
    "(`w` is not used, only necessary for the consistency of the function interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbab3de-4767-45c9-a4d3-6bfb638d243a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:13:11.246925509Z",
     "start_time": "2024-02-01T08:13:11.242962Z"
    }
   },
   "outputs": [],
   "source": [
    "def getCostFunctionPINN(x, xB, u, uB, w, wB, EA, distLoad, uBLabel):\n",
    "    differentialEquationLoss = getDerivative(\n",
    "        EA(x) * getDerivative(u, x, 1), x, 1\n",
    "    ) + distLoad(x)\n",
    "    differentialEquationLoss = torch.sum(differentialEquationLoss ** 2).squeeze()\n",
    "\n",
    "    # initialization\n",
    "    boundaryConditionLoss = 0\n",
    "\n",
    "    for i in range(len(uBLabel)):\n",
    "        boundaryConditionLoss += (\n",
    "                                         getDerivative(uB, xB, uBLabel[i][1])[i] - uBLabel[i][0]\n",
    "                                 ).squeeze() ** 2\n",
    "\n",
    "    return differentialEquationLoss + boundaryConditionLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5499a4-27cf-4c26-9757-7961185bc4b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:13:11.267797707Z",
     "start_time": "2024-02-01T08:13:11.247111920Z"
    }
   },
   "outputs": [],
   "source": [
    "def getCostFunctionDGM(x, xB, u, uB, w, wB, EA, distLoad, uBLabel):\n",
    "    differentialEquationLoss = getDerivative(\n",
    "        EA(x) * getDerivative(u, x, 1), x, 1\n",
    "    ) + distLoad(x)\n",
    "    v = torch.rand(u.shape) * torch.max(\n",
    "        x\n",
    "    )  # optional positive probability density for differential equation loss\n",
    "    differentialEquationLoss = getIntegral(\n",
    "        differentialEquationLoss ** 2 * v, x\n",
    "    ).squeeze()  # boundary points are treated separately [1:-1]\n",
    "\n",
    "    # initialization\n",
    "    boundaryConditionLoss = 0\n",
    "\n",
    "    for i in range(len(uBLabel)):\n",
    "        boundaryConditionLoss += (\n",
    "                                         getDerivative(uB, xB, uBLabel[i][1])[i] - uBLabel[i][0]\n",
    "                                 ).squeeze() ** 2\n",
    "\n",
    "    return differentialEquationLoss + boundaryConditionLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779eca17-e9ef-4117-b846-9773a827bf46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:13:11.268725628Z",
     "start_time": "2024-02-01T08:13:11.259229752Z"
    }
   },
   "outputs": [],
   "source": [
    "def getCostFunctionVPINN(x, xB, u, uB, w, wB, EA, distLoad, uBLabel):\n",
    "    # derivative computation\n",
    "    dwdx = torch.zeros(w.shape)\n",
    "    for i in range(w.shape[1]):\n",
    "        dwdx[:, i: (i + 1)] = getDerivative(w[:, i: (i + 1)], x, 1)\n",
    "\n",
    "    integrand = dwdx * EA(x) * getDerivative(u, x, 1)\n",
    "    cost_ = -getIntegral(integrand, x)  # boundary points are treated separately [1:-1]\n",
    "\n",
    "    integrand = w * distLoad(x)\n",
    "    cost_ += getIntegral(integrand, x)  # boundary points are treated separately [1:-1]\n",
    "\n",
    "    for i in range(len(uB)):\n",
    "        if uBLabel[i][1] == 1:\n",
    "            cost_ += wB[i] * EA(uBLabel[i][2]) * uBLabel[i][0]\n",
    "\n",
    "    cost = torch.sum(cost_ ** 2)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea0c4e0-3ff0-493e-8f6c-3a3de396b189",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:13:11.283015315Z",
     "start_time": "2024-02-01T08:13:11.268212591Z"
    }
   },
   "outputs": [],
   "source": [
    "def getCostFunctionDEM(\n",
    "        x, xB, u, uB, w, wB, EA, distLoad, uBLabel\n",
    "):  # w is not used, only necessary for the consistency of the function interface\n",
    "    strain = getDerivative(u, x, 1)\n",
    "\n",
    "    internalEnergyDensity = 0.5 * EA(x) * strain ** 2\n",
    "    internalEnergy = getIntegral(internalEnergyDensity, x)\n",
    "\n",
    "    externalEnergyDistLoad = -getIntegral((distLoad(x) * u), x)\n",
    "    externalEnergyNeumannBC = torch.tensor([0.0])\n",
    "    for i in range(len(uB)):\n",
    "        if uBLabel[i][1] == 1:\n",
    "            externalEnergyNeumannBC -= (\n",
    "                    uB[i] * EA(uBLabel[i][2]) * uBLabel[i][0]\n",
    "            )  # OBS CHECK IF YOU HAVE TO ADD EA HERE\n",
    "    externalEnergy = externalEnergyDistLoad + externalEnergyNeumannBC\n",
    "\n",
    "    return internalEnergy + externalEnergy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dc0fd4-dc6c-41d3-92ad-44c503330933",
   "metadata": {},
   "source": [
    "**select PINN variation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad2ef3-ee11-4d49-8bd8-b9e1597ac6aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:13:11.292848350Z",
     "start_time": "2024-02-01T08:13:11.282853761Z"
    }
   },
   "outputs": [],
   "source": [
    "getCostFunction = getCostFunctionPINN\n",
    "# getCostFunction = getCostFunctionDGM\n",
    "# getCostFunction = getCostFunctionDEM\n",
    "# getCostFunction = getCostFunctionVPINN\n",
    "# for WAN go to block 18 and use getCostFunctionVPINN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4e7265-83d4-4be6-b5d2-018649c32b21",
   "metadata": {},
   "source": [
    "## Problem setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2957569f-3de2-43dd-9b11-3221bf3d04b9",
   "metadata": {},
   "source": [
    "**physical parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7459465-221f-43d6-8c9f-0d7ff6938496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:13:11.304579571Z",
     "start_time": "2024-02-01T08:13:11.292686381Z"
    }
   },
   "outputs": [],
   "source": [
    "# Problem a\n",
    "# Analytial solution\n",
    "uAnalytic = lambda x: (1.0 - np.cos(3.0 * np.pi * x))\n",
    "\n",
    "# Problem data\n",
    "E = lambda x: 2.0 + x * 0  # Young's modulus\n",
    "A = lambda x: 1.0 + x * 0  # cross-sectional area\n",
    "L = 1  # bar length\n",
    "# boundary conditions: [value, degree of differentiation, coordinate] (Boundaries conditions can only be set at 0 and -1, maximum degree of differentiation is 1)\n",
    "uB = [\n",
    "    [0, 0, 0],\n",
    "    [3 * np.pi * np.sin(3 * np.pi * L), 1, L],\n",
    "]  # Neumann boundary condition becomes homogeneous for L=1\n",
    "distLoad = (\n",
    "    lambda x: -18 * np.pi ** 2 * torch.cos(3 * np.pi * x)\n",
    ")  # distributed load p(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f533b6-272e-460a-8355-0850025d400f",
   "metadata": {},
   "source": [
    "**hyperparameters**\n",
    "\n",
    "currently Adam is selected as optimizer. By commenting the Adam block and uncommenting the L-BFGS block, you can enable L-BFGS as optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15917078-13cb-4725-9164-cf409ada9530",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:13:11.309165617Z",
     "start_time": "2024-02-01T08:13:11.296865564Z"
    }
   },
   "outputs": [],
   "source": [
    "Nx = 100  # number of collocation points\n",
    "hiddenDimensions = [100]  # definition of hidden layers\n",
    "activationFunction = (\n",
    "    torch.nn.Tanh()\n",
    ")  # if this is changed, also adapt the initialization\n",
    "\n",
    "epochs = 4000  # number of epochs\n",
    "lr = 1e-2  # 1e-2 # learning rate\n",
    "selectOptimizer = \"Adam\"\n",
    "\n",
    "# epochs = 500\n",
    "# selectOptimizer = \"LBFGS\"\n",
    "# lr = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2fddfc-395b-4339-bebe-6558fde75679",
   "metadata": {},
   "source": [
    "**training grid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8609cae-76eb-450e-9b84-75a69068c7a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:13:11.331182327Z",
     "start_time": "2024-02-01T08:13:11.308893596Z"
    }
   },
   "outputs": [],
   "source": [
    "if getIntegral == midpointIntegration:\n",
    "    dx = L / (Nx)\n",
    "    x = torch.linspace(0.5 * dx, L - 0.5 * dx, Nx - 2, requires_grad=True).unsqueeze(1)\n",
    "else:\n",
    "    x = torch.linspace(0, L, Nx - 2, requires_grad=True).unsqueeze(1)\n",
    "\n",
    "# boundary points\n",
    "xB = torch.tensor([uBi[2] for uBi in uB]).unsqueeze(1).to(torch.float32)\n",
    "xB.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b309db2e-aa72-4e72-bbd5-0d1df04fa0bf",
   "metadata": {},
   "source": [
    "**neural network & optimizer setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66f248-a5c1-4ca7-8552-41ffbe2e7828",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:13:11.346875495Z",
     "start_time": "2024-02-01T08:13:11.330896100Z"
    }
   },
   "outputs": [],
   "source": [
    "modelU = NN(1, hiddenDimensions, 1, activationFunction)\n",
    "modelU.apply(initWeights)\n",
    "\n",
    "# for VPINN\n",
    "n = 10\n",
    "modelW = testFunctions(x, n, L)\n",
    "\n",
    "# for WAN\n",
    "# n = 10\n",
    "# modelW = NN(1, hiddenDimensions, n, activationFunction)\n",
    "# modelW.apply(initWeights)\n",
    "\n",
    "if selectOptimizer == \"Adam\":\n",
    "    optimizer = torch.optim.Adam(modelU.parameters(), lr)\n",
    "elif selectOptimizer == \"LBFGS\":\n",
    "    optimizer = torch.optim.LBFGS(modelU.parameters(), lr)\n",
    "\n",
    "if modelW.parameters() != None:\n",
    "    optimizer = torch.optim.Adam(\n",
    "        list(modelU.parameters()) + list(modelW.parameters()), lr\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f755e-e923-49d3-954c-bf09cd8ee74d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96bca03-41d4-4a84-9945-326f7f59c3a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:14:31.141405692Z",
     "start_time": "2024-02-01T08:13:11.346367885Z"
    }
   },
   "outputs": [],
   "source": [
    "costHistory = np.zeros(epochs)\n",
    "\n",
    "start = time.perf_counter()\n",
    "start0 = start\n",
    "for epoch in range(epochs):\n",
    "    # predict displacements\n",
    "    uPred = getDisplacements(modelU, x, uB, L)\n",
    "    uBPred = getDisplacements(modelU, xB, uB, L)\n",
    "    wPred = getTestFunctions(modelW, x, uB, L)  # modelW(x)\n",
    "    wBPred = getTestFunctions(modelW, x, uB, L)  # modelW(xB)\n",
    "\n",
    "    costHistory[epoch] = getCostFunction(\n",
    "        x, xB, uPred, uBPred, wPred, wBPred, lambda x: E(x) * A(x), distLoad, uB\n",
    "    ).detach()\n",
    "\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        uPred = getDisplacements(modelU, x, uB, L)\n",
    "        uBPred = getDisplacements(modelU, xB, uB, L)\n",
    "        wPred = getTestFunctions(modelW, x, uB, L)  # modelW(x)\n",
    "        cost = getCostFunction(\n",
    "            x, xB, uPred, uBPred, wPred, wBPred, lambda x: E(x) * A(x), distLoad, uB\n",
    "        )\n",
    "        cost.backward(retain_graph=True)\n",
    "        if modelW.parameters() != None:\n",
    "            for i in range(len(list(modelW.parameters()))):\n",
    "                list(modelW.parameters())[i].grad = (\n",
    "                        -list(modelW.parameters())[i].grad * 1e0\n",
    "                )  # maximization with regard to test function, gradients can be scaled\n",
    "        return cost\n",
    "\n",
    "\n",
    "    optimizer.step(closure)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        elapsedTime = (time.perf_counter() - start) / 100\n",
    "        string = \"Epoch: {}/{}\\t\\tCost = {:2e}\\t\\tElapsed time per epoch = {:2f}\"\n",
    "        # Format string and print\n",
    "        print(string.format(epoch, epochs - 1, costHistory[epoch], elapsedTime))\n",
    "        start = time.perf_counter()\n",
    "elapsedTime = time.perf_counter() - start0\n",
    "string = \"Total elapsed time: {:2f}\\nAverage elapsed time per epoch: {:2f}\"\n",
    "print(string.format(elapsedTime, elapsedTime / epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e63a9d-ea31-4930-90bb-b429637ca35c",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b677c7-9d31-4451-8562-8aa347e04726",
   "metadata": {},
   "source": [
    "**training history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a6c235-0210-40aa-a4d4-b93afc51989f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:14:31.411634078Z",
     "start_time": "2024-02-01T08:14:31.151420508Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Cost function $C$\")\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "ax.plot(costHistory, \"k\", linewidth=2, label=\"Cost $C$\")\n",
    "\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954f6de0-2ef2-4c1d-bad3-714c954ac14f",
   "metadata": {},
   "source": [
    "**displacement prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd55fa0-2d9e-4e79-be43-3f4164db12ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T08:14:31.578470Z",
     "start_time": "2024-02-01T08:14:31.414871116Z"
    }
   },
   "outputs": [],
   "source": [
    "xTest = torch.linspace(0, L, 1000).unsqueeze(1)\n",
    "uPredTest = getDisplacements(modelU, xTest, uB, L).detach()\n",
    "uPred = getDisplacements(modelU, x, uB, L).detach()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"$x$\")\n",
    "ax.set_ylabel(\"Displacement $u$\")\n",
    "\n",
    "ax.plot(xTest, uAnalytic(xTest), \"gray\", linewidth=2, label=\"Analytical solution\")\n",
    "ax.plot(xTest, uPredTest, \"k:\", linewidth=2, label=\"Prediction\")\n",
    "ax.plot(x.detach(), uPred, \"rs\", markersize=6, label=\"Collocation points\")\n",
    "\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
